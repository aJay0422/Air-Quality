{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import scipy.linalg as linalg\n",
    "\n",
    "from haversine import haversine\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "from time import time\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.nn import MessagePassing, GATConv\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "project_dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "from utils.data import load_data\n",
    "from utils.tool import prediction_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File1: 3BAGEmnnQ2K4zF49Dkkoxg.csv contains missing hours\n",
      "File4: 4XEJFVFOS761cvyEjOYf0g.csv contains outliers\n",
      "File5: 6kzhfU9xTKCUVJMz492l2g.csv contains outliers\n",
      "File6: 6nBLCf6WT06TOuUExPkBtA.csv contains missing hours\n",
      "File17: JQ1px-xqQx-xKh3Oa5h9nA.csv contains missing hours\n",
      "File21: OfAvTbS1SiOjQo4WKSAP9g.csv contains missing hours\n",
      "File24: R2ebpAblQHylOjteA-2hlQ.csv contains missing hours\n",
      "File37: jDYxIP2JQL2br5aTIAR7JQ.csv contains outliers\n",
      "File38: kyRUtBOTTaK7V_-dxOJTwg.csv contains outliers\n",
      "File45: wSo2iRgjT36eWC4a2joWZg.csv contains outliers\n"
     ]
    }
   ],
   "source": [
    "os.chdir(project_dir)\n",
    "train_loader, val_loader, test_loader = load_data(window=2, batch_size=32)\n",
    "os.chdir(os.path.join(project_dir, 'models/GNN12'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGraphDataset(Dataset):\n",
    "    def __init__(self, graphs):\n",
    "        super(MyGraphDataset, self).__init__()\n",
    "        self.graphs = graphs\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.graphs[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def get_edge_index(n):\n",
    "    \"\"\"\n",
    "    Create edge index for a complete graph of n nodes with self loops\n",
    "    :param n: number of nodes\n",
    "    :return: edge index tensor\n",
    "    \"\"\"\n",
    "    edge_index = torch.tensor([[i, j] for i in range(n) for j in range(n)], dtype=torch.long).t().contiguous()\n",
    "    return edge_index\n",
    "\n",
    "def get_distance_matrix(locs):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance matrix\n",
    "    :param locs: a torch tensor of size (batch_size, num_nodes, 2) or (num_nodes, 2)\n",
    "    \"\"\"\n",
    "    if len(locs.size()) == 2:\n",
    "        batch = False\n",
    "        locs = locs.unsqueeze(0)\n",
    "    else:\n",
    "        batch = True\n",
    "\n",
    "\n",
    "    B, N, _ = locs.size()\n",
    "    locs_i = locs.unsqueeze(2).expand(B, N, N, 2)\n",
    "    locs_j = locs.unsqueeze(1).expand(B, N, N, 2)\n",
    "    distances = torch.sqrt(((locs_i - locs_j) ** 2).sum(dim=-1))\n",
    "\n",
    "    if not batch:\n",
    "        distances = distances.squeeze(0)\n",
    "    \n",
    "    return distances\n",
    "\n",
    "# Following 2 functions adapted from https://github.com/nnzhan/Graph-WaveNet/blob/master/util.py\n",
    "def calculate_scaled_laplacian(adj_mx, lambda_max=2, undirected=False):\n",
    "    def calculate_normalized_laplacian(adj):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        adj = sp.coo_matrix(adj)\n",
    "        d = np.array(adj.sum(1))\n",
    "        d_inv_sqrt = np.power(d, -0.5).flatten()\n",
    "        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "        normalized_laplacian = sp.eye(adj.shape[0]) - adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "        return normalized_laplacian\n",
    "    if undirected:\n",
    "        adj_mx = np.maximum.reduce([adj_mx, adj_mx.T])\n",
    "    L = calculate_normalized_laplacian(adj_mx)\n",
    "    if lambda_max is None:\n",
    "        lambda_max, _ = linalg.eigsh(L, 1, which='LM')\n",
    "        lambda_max = lambda_max[0]\n",
    "    L = sp.csr_matrix(L)\n",
    "    M, _ = L.shape\n",
    "    I = sp.identity(M, format='csr', dtype=L.dtype)\n",
    "    L = (2 / lambda_max * L) - I\n",
    "    return L.astype(np.float32).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Mlp, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, 2 * out_dim),\n",
    "            nn.BatchNorm1d(2 * out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * out_dim, out_dim),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "    \n",
    "\n",
    "class LocalLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, heads=4, dropout=0.2):\n",
    "        super(LocalLayer, self).__init__()\n",
    "        self.conv1 = GATConv(in_dim, out_dim, heads=heads, dropout=dropout)\n",
    "        self.conv2 = GATConv(4 * out_dim, out_dim, heads=heads, dropout=dropout, concat=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class DiffusionLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(DiffusionLayer, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        self.mlp = Mlp(in_dim, out_dim)\n",
    "\n",
    "        self.k = Parameter(torch.Tensor(1, out_dim))\n",
    "\n",
    "    def forward(self, locs, features):\n",
    "        \"\"\"\n",
    "        :param locs: (B, N, 2)\n",
    "        :param features: (B, N, in_dim)\n",
    "        \"\"\"\n",
    "        B, N, D = features.size()\n",
    "\n",
    "        # apply mlp to features\n",
    "        features = rearrange(features, 'b n d -> (b n) d')\n",
    "        features = self.mlp(features)\n",
    "        features = rearrange(features, '(b n) d -> b n d', b=B)\n",
    "\n",
    "        # calculate the scaled laplacian\n",
    "        L = np.zeros((B, N, N))\n",
    "        for b in range(B):\n",
    "            D = get_distance_matrix(locs[b])\n",
    "            W = 1 / (D + 1e-8)\n",
    "            # Set diagonal elements to 0\n",
    "            mask = torch.ones(N, N).to(features.device) - torch.eye(N).to(features.device)\n",
    "            W = W * mask\n",
    "            L_temp = calculate_scaled_laplacian(W.cpu().numpy())\n",
    "            L[b] = torch.tensor(L_temp).to(features.device)\n",
    "\n",
    "        # apply diffusion\n",
    "        L = torch.from_numpy(L).to(features.device).float()   # (B, N, N)\n",
    "        outputs = torch.bmm(L, features) * self.k\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "class ConvectionLayer(MessagePassing):\n",
    "    def __init__(self, in_dim, out_dim, edge_dim):\n",
    "        super(ConvectionLayer, self).__init__(aggr='mean')\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.edge_in_dim = edge_dim\n",
    "\n",
    "        self.node_linear = Mlp(in_dim, out_dim)\n",
    "        self.edge_linear = Mlp(edge_dim, out_dim)\n",
    "        self.message_linear = Mlp(2 * out_dim, out_dim)\n",
    "        self.update_linear = Mlp(2 * out_dim, out_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        :param x: node features of shape (num_nodes, in_dim)\n",
    "        :param edge_index: edge index tensor of shape (2, num_edges)\n",
    "        :param edge_attr: edge features of shape (num_edges, edge_dim)\n",
    "        \"\"\"\n",
    "        assert len(x.size()) == len(edge_attr.size()) == 2, \"x and edge_attr must have 2 dimensions\"\n",
    "        assert edge_index.size(1) == edge_attr.size(0), \"edge_index and edge_attr must have the same number of edges\"\n",
    "\n",
    "        N = x.size(0)\n",
    "        # transform node and edge features\n",
    "        x = self.node_linear(x)\n",
    "        edge_attr = self.edge_linear(edge_attr)\n",
    "\n",
    "        outputs = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "        return outputs, edge_attr\n",
    "    \n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        \"\"\"\n",
    "        Edge from j -> i\n",
    "        \"\"\"\n",
    "        x_i = x_i + edge_attr\n",
    "        x_j = x_j + edge_attr\n",
    "        x = torch.cat([x_i, x_j], dim=-1)\n",
    "        return self.message_linear(x) + x_i\n",
    "    \n",
    "    def update(self, aggr_out, x):\n",
    "        x_cat = torch.cat([aggr_out, x], dim=-1)\n",
    "        return self.update_linear(x_cat) + x\n",
    "    \n",
    "\n",
    "class LCDLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, edge_dim):\n",
    "        super(LCDLayer, self).__init__()\n",
    "\n",
    "        self.local = LocalLayer(in_dim, out_dim)\n",
    "        self.convection = ConvectionLayer(in_dim, out_dim, edge_dim)\n",
    "        self.diffusion = DiffusionLayer(in_dim, out_dim)\n",
    "\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(3 * out_dim, 3),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, locs, features, winds_feature, edge_index):\n",
    "        \"\"\"\n",
    "        :param locs: a torch tensor of size (B, N, 2)\n",
    "        :param features: a torch tensor of size (B, N, in_dim)\n",
    "        :param winds_feature: a torch tensor of size (B, N^2, in_dim)\n",
    "        :param edge_index: a torch tensor of size (2, N^2)\n",
    "        \"\"\"\n",
    "        B, N, _ = locs.size()\n",
    "        # preprocess the input data into a batch\n",
    "        batch = self.batch_preprocess(locs, features, winds_feature, edge_index)\n",
    "\n",
    "        # input original feature to nn.Module and batch features to MessagePassing\n",
    "        l_features = self.local(batch.features, batch.edge_index)\n",
    "        c_features, edge_attr = self.convection(batch.features, batch.edge_index, batch.winds_feature)\n",
    "        d_features = self.diffusion(locs, features)\n",
    "\n",
    "        # reverse the batched outputs\n",
    "        l_features = self.reverse_batch_process(l_features, B=B)\n",
    "        c_features, edge_attr = self.reverse_batch_process(c_features, edge_attr, B=B)\n",
    "\n",
    "        # fusion\n",
    "        weights = self.fusion(torch.cat([l_features, c_features, d_features], dim=-1))   # (B, N, 3)\n",
    "        outputs = l_features * weights[:, :, 0].unsqueeze(-1) + c_features * weights[:, :, 1].unsqueeze(-1) + d_features * weights[:, :, 2].unsqueeze(-1)\n",
    "\n",
    "        return outputs, edge_attr\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def batch_preprocess(locs, features, winds_feature, edge_index):\n",
    "        \"\"\"\n",
    "        Preprocess the input data into a single batch\n",
    "        \"\"\"\n",
    "        B, N, _ = locs.size()\n",
    "        graphs = []\n",
    "        for b in range(B):\n",
    "            graph = Data(features=features[b],\n",
    "                         edge_index=edge_index,\n",
    "                         locs=locs[b],\n",
    "                         winds_feature=winds_feature[b],\n",
    "                         num_nodes=N)\n",
    "            graphs.append(graph)\n",
    "        graphs = MyGraphDataset(graphs)\n",
    "        loader = DataLoader(graphs, batch_size=B, shuffle=False)\n",
    "        return next(iter(loader))\n",
    "    \n",
    "    @staticmethod\n",
    "    def reverse_batch_process(features, edge_attr=None, B=32):\n",
    "        \"\"\"\n",
    "        Reverse the batch process\n",
    "        :param features: a torch tensor of size (B*N, out_dim)\n",
    "        :param edge_attr: a torch tensor of size (B*N**2, edge_dim)\n",
    "        \"\"\"\n",
    "        N = features.size(0) // B\n",
    "        features = rearrange(features, '(b n) d -> b n d', b=B)\n",
    "        if edge_attr is not None:\n",
    "            edge_attr = rearrange(edge_attr, '(b m) d -> b m d', b=B)\n",
    "            return features, edge_attr\n",
    "        return features\n",
    "\n",
    "\n",
    "class LCDGCN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim=1,\n",
    "                 hidden_dim=64,\n",
    "                 out_dim=1,\n",
    "                 num_layers=3,\n",
    "                 edge_dim=3):\n",
    "        super(LCDGCN, self).__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(LCDLayer(in_dim, hidden_dim, edge_dim))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(LCDLayer(hidden_dim, hidden_dim, hidden_dim))\n",
    "        self.layers.append(LCDLayer(hidden_dim, out_dim, hidden_dim))\n",
    "\n",
    "    def forward(self, locs, readings, target_loc, winds_feature, edge_index):\n",
    "        \"\"\"\n",
    "        :param locs: a torch tensor of size (B, N, 2)\n",
    "        :param readings: a torch tensor of size (B, N, in_dim, 2). Here 2 stands for 2 time steps\n",
    "        :param target_loc: a torch tensor of size (B, 2)\n",
    "        :param winds_feature: a torch tensor of size (B, N+1, N+1, edge_dim)\n",
    "        \"\"\"\n",
    "        B, N, D, T = readings.size()\n",
    "        assert N == winds_feature.size(1) - 1, f\"The number of nodes in winds_feature({winds_feature.size(1)}) should be 1 plus that in readings({N})\"\n",
    "\n",
    "        # preprocess edge features\n",
    "        winds_feature = self.preprocess_edge_features(winds_feature)\n",
    "\n",
    "        # concat and mask\n",
    "        lcd_locs = torch.cat([locs, target_loc[:, None, :]], dim=1)   # (B, N+1, 2)\n",
    "        lcd_readings = torch.cat([readings[:, :, :, 1],\n",
    "                                  torch.zeros(B, 1, D).to(readings.device)],\n",
    "                                  dim=1)   # (B, N+1, D)\n",
    "        \n",
    "        # forward pass\n",
    "        for layer in self.layers:\n",
    "            lcd_readings, winds_feature = layer(lcd_locs, lcd_readings, winds_feature, edge_index)\n",
    "        outputs = lcd_readings\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_edge_features(edge_features):\n",
    "        \"\"\"\n",
    "        Transform edge features from shape (B, N, N, D) to (B, N^2, D)\n",
    "        \"\"\"\n",
    "        assert len(edge_features.size()) == 4\n",
    "        assert edge_features.size(1) == edge_features.size(2)\n",
    "        B, N, _, D = edge_features.size()\n",
    "        edge_features = edge_features.view(B, N * N, D)\n",
    "        return edge_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 256\n",
    "num_layers = 3\n",
    "\n",
    "# set seed for model initialization\n",
    "seedi = 45\n",
    "torch.manual_seed(seedi)\n",
    "model = LCDGCN(in_dim=1,\n",
    "               hidden_dim=hidden_dim,\n",
    "               out_dim=1,\n",
    "               num_layers=num_layers,\n",
    "               edge_dim=3)\n",
    "\n",
    "# set up training\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2562 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2562/2562 [1:39:43<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 62.8751, Validation Loss: 67.0454\n",
      "Save the best model at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2562/2562 [1:49:49<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Training Loss: 42.4238, Validation Loss: 33.3892\n",
      "Save the best model at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2562/2562 [1:50:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Training Loss: 30.6087, Validation Loss: 32.0974\n",
      "Save the best model at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2562/2562 [1:41:29<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Training Loss: 25.8306, Validation Loss: 33.6697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 693/2562 [58:48<2:38:37,  5.09s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# backward\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# validation\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env_ai/lib/python3.8/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env_ai/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set seed for training\n",
    "seedt = 45\n",
    "torch.manual_seed(seedt)\n",
    "\n",
    "# set weight path\n",
    "save_path = f\"./weights/LCDGCN_h{hidden_dim}_l{num_layers}_si{seedi}_st{seedt}.pth\"\n",
    "\n",
    "# training\n",
    "best_val = 1e10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch in tqdm(train_loader):\n",
    "        locs, readings, target_loc, target_reading, winds_feature = batch\n",
    "        readings_input = readings[..., None].permute(0, 2, 3, 1)   # (B, N, 1, 2)\n",
    "        winds_feature_input = winds_feature[:, :, :, 0, :]   # (B, N+1, N+1, 3)\n",
    "        pred_target = torch.cat([readings.permute(0, 2, 1)[:, :, 1:],\n",
    "                                 target_reading[:, 1:].unsqueeze(1)],\n",
    "                                 dim=1)   # (B, N+1, 1)\n",
    "        edge_index = get_edge_index(pred_target.size(1))\n",
    "\n",
    "        # forward\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(locs, readings_input, target_loc, winds_feature_input, edge_index)\n",
    "\n",
    "        # loss\n",
    "        loss = criterion(pred[:, -1], pred_target[:, -1])\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # validation\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            locs, readings, target_loc, target_reading, winds_feature = batch\n",
    "            readings_input = readings[..., None].permute(0, 2, 3, 1)\n",
    "            winds_feature_input = winds_feature[:, :, :, 0, :]\n",
    "            pred_target = torch.cat([readings.permute(0, 2, 1)[:, :, 1:],\n",
    "                                     target_reading[:, 1:].unsqueeze(1)],\n",
    "                                     dim=1)\n",
    "            edge_index = get_edge_index(pred_target.size(1))\n",
    "\n",
    "            # forward\n",
    "            pred = model(locs, readings_input, target_loc, winds_feature_input, edge_index)\n",
    "\n",
    "            # loss\n",
    "            loss = criterion(pred[:, -1], pred_target[:, -1])\n",
    "            val_losses.append(loss.item())\n",
    "        \n",
    "        # print training and validation losses\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {np.mean(losses):.4f}, Validation Loss: {np.mean(val_losses):.4f}\")\n",
    "\n",
    "        # save the best model\n",
    "        if np.mean(val_losses) < best_val:\n",
    "            best_val = np.mean(val_losses)\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Save the best model at epoch {epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
